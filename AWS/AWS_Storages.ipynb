{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce4a790-6442-4ea7-96c6-7e2feef0d08b",
   "metadata": {},
   "source": [
    "# Why Different Types of Storage needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd11cc-9a0e-458e-acfd-4615703c6603",
   "metadata": {},
   "source": [
    "There are three storages which are most popular \n",
    "\n",
    "- EBS\n",
    "- EFS\n",
    "- S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56799e04-3f9b-43c0-8f99-d9735deed0aa",
   "metadata": {},
   "source": [
    "### EBS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a59f-0f9d-4c32-809e-8fb9fd29135b",
   "metadata": {},
   "source": [
    "EBS is like a virtual hard drive that can be attached to an EC2 instance. This virtual hard drive can be resized and modified as needed, just like a physical hard drive. EBS volumes are designed to be durable, which means that your data is stored reliably and can be easily recovered if something goes wrong. Additionally, EBS volumes are optimized for low-latency, high-performance storage, which makes them ideal for running mission-critical applications that require fast and reliable storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29af34-2fc5-487a-94dc-bcf2d1e53f2c",
   "metadata": {},
   "source": [
    "### EFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a363f-b664-469d-9533-c27172c4e9f1",
   "metadata": {},
   "source": [
    "EFS is like a virtual \"file server\" that can be accessed by multiple computers or servers, just like a traditional file server in an office. With EFS, you can easily store and manage files in the cloud, and share them across multiple instances without having to manage your own file server.\n",
    "\n",
    "EFS is designed to be highly scalable and durable, which means that you can store a large number of files and access them quickly and reliably from anywhere. It also provides a range of security features to help you keep your files safe and secure.\n",
    "\n",
    "Overall, EFS is a simple and easy-to-use file storage service that allows you to store and access files in the cloud just like you would with a traditional file server, but without the hassle of managing your own infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276513d4-fc95-482b-9d57-49d41dc07305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5687cad-8f22-447d-8d58-ee5ecbf01246",
   "metadata": {},
   "source": [
    "# S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f7a1c-c4f6-458c-9d63-aca81409c00d",
   "metadata": {},
   "source": [
    "Amazon S3 is like a big digital warehouse where you can store all kinds of digital objects, like files, images, videos, and data. You can store as many objects as you want, and they can be as big as 5 terabytes each.\n",
    "\n",
    "To access the objects in the warehouse, you just need a unique address for each one, which is called a key. You can access the objects from anywhere in the world, as long as you have an internet connection and the right permissions.\n",
    "\n",
    "The warehouse is designed to be very secure, with multiple layers of protection, including encryption, access controls, and monitoring. It is also designed to be very reliable, with redundant copies of all objects stored in multiple locations, so you can be confident that your data is safe and available when you need it.\n",
    "\n",
    "The warehouse is also very flexible, with different storage classes and pricing options to choose from based on your needs. For example, you can choose to store objects that you access frequently in a high-performance storage class, or objects that you access infrequently in a lower-cost storage class.\n",
    "\n",
    "Overall, Amazon S3 is a very powerful and flexible storage solution that can help you store and manage your digital objects with ease and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b604a7-6f8f-4ba6-ba92-8311d33ccb22",
   "metadata": {},
   "source": [
    "### Buckets and Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749fba0-c79d-491d-8390-261313251de7",
   "metadata": {},
   "source": [
    "In Amazon S3, data is organized into \"buckets\" and \"objects\".\n",
    "\n",
    "A bucket is a container for storing objects. Every object is contained within a bucket, and you can have many objects within a bucket. Buckets are globally unique, meaning that the name of each bucket must be unique across all AWS accounts. You can create buckets using the S3 console or programmatically using the AWS SDKs or the S3 REST API.\n",
    "\n",
    "An object is the fundamental entity stored in Amazon S3. It represents a file and its metadata. An object consists of data (which can be anything from a few bytes to many terabytes), a key (a unique identifier that represents the object within the bucket), and metadata (which can include things like content type, date created, and custom metadata that you define). Objects can be uploaded to and downloaded from S3 using the AWS Management Console, SDKs, or REST API.\n",
    "\n",
    "When you store an object in Amazon S3, you can control access to the object using access policies, bucket policies, and access control lists (ACLs). You can also configure lifecycle policies to automatically transition objects between different storage classes or delete them when they are no longer needed.\n",
    "\n",
    "Overall, buckets and objects are the fundamental building blocks of Amazon S3. They provide a simple and scalable way to store and retrieve data in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0965f-1c33-4154-b012-f15536f49282",
   "metadata": {},
   "source": [
    "### Bucket Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5359e2-e06c-4631-abfd-40e412c640f2",
   "metadata": {},
   "source": [
    "Bucket versioning is a feature in Amazon S3 that allows you to keep multiple versions of an object in the same S3 bucket. When versioning is enabled, every time you upload a new version of an object to the bucket, S3 automatically creates a new version of the object and keeps the older version(s) intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1b327-2874-4f0b-b526-0c81a8df0f4d",
   "metadata": {},
   "source": [
    "### Intelligent Tiering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040c32a-7532-47c8-ad9b-08dee0593b70",
   "metadata": {},
   "source": [
    "Intelligent-Tiering is a storage class in Amazon S3 that automatically moves objects between two access tiers (frequent access and infrequent access) based on changing access patterns and usage.\n",
    "Intelligent-Tiering is a storage feature in Amazon S3 that automatically moves your data between two different storage tiers based on how often you access it. The two storage tiers are the frequent access tier, which is for data that you access often, and the infrequent access tier, which is for data that you access less frequently.\n",
    "\n",
    "The Archive access tier is a third storage tier that is designed for long-term data retention and archiving. It is intended for data that you don't need to access very often but need to keep for a long time, such as backup files or historical records.\n",
    "\n",
    "With Intelligent-Tiering with Archive access tier, you don't have to manually move your data between different storage tiers. Instead, S3 automatically moves your data to the most cost-effective tier based on your usage patterns. This means that you can save money on storage costs without sacrificing accessibility or durability.\n",
    "\n",
    "The Archive access tier has a minimum storage duration of 90 days, which means that you will be charged for storing your data for at least that amount of time. Retrieval of data from the Archive access tier can take minutes to hours, so it's not suitable for data that needs to be accessed frequently.\n",
    "S3 Intelligent-Tiering also includes the Archive access tier, which is designed for long-term data retention and archiving. When you configure an object with Intelligent-Tiering storage class, S3 monitors the access patterns of the object, and automatically moves the object to the most cost-effective access tier based on access frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a7b5-1824-4cba-b35a-e6f5d867f57b",
   "metadata": {},
   "source": [
    "### Bucket Policiees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaceceb-57cc-44a6-8ab3-26506eab6880",
   "metadata": {},
   "source": [
    "A bucket policy is a set of rules that you can apply to an Amazon S3 bucket to control access to the objects in the bucket. With a bucket policy, you can specify who can access your bucket and what actions they can perform on the objects in the bucket.\n",
    "\n",
    "Here are some key points to understand about bucket policies:\n",
    "\n",
    "Bucket policies are written in JSON format: A bucket policy is a JSON document that specifies the access rules for the bucket. You can write the policy yourself, or use the AWS Management Console to generate a policy for you.\n",
    "\n",
    "Bucket policies are applied to the entire bucket: When you apply a bucket policy, it applies to all objects in the bucket, regardless of who owns the objects.\n",
    "\n",
    "Bucket policies can control access based on various criteria: You can use a bucket policy to control access based on the requester's IP address, AWS account ID, IAM user, or IAM role.\n",
    "\n",
    "Bucket policies can grant or deny access: A bucket policy can either grant or deny access to the objects in the bucket. You can specify which actions are allowed or denied, such as GET or PUT, and you can specify whether the actions apply to the bucket or the objects in the bucket.\n",
    "\n",
    "Bucket policies can be used in combination with other access controls: You can use bucket policies in combination with other access controls, such as IAM policies or access control lists (ACLs), to further refine access to your bucket and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efd0bc-d34c-499c-b7a3-57611cdbd571",
   "metadata": {},
   "source": [
    "### Lifecycle Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470a574-17e5-403a-812d-c05139ba9f8a",
   "metadata": {},
   "source": [
    "Lifecycle rules are a feature that allow you to manage your objects by automatically moving them between different storage classes or deleting them based on certain criteria.\n",
    "\n",
    "When you create a lifecycle rule, it applies to all objects within a specific S3 bucket. You can use lifecycle rules to move objects between different storage classes based on their age or other criteria such as object size or tags. Additionally, you can use lifecycle rules to delete objects that are no longer needed, such as after a certain amount of time has passed.\n",
    "\n",
    "Lifecycle rules can help you save costs by automatically moving your objects to a lower-cost storage class as they age, and they can also help you ensure that your objects are stored in the most appropriate storage class at any given time.\n",
    "\n",
    "You can create lifecycle rules using the AWS Management Console or programmatically using the S3 API or AWS SDKs. By using lifecycle rules, you can automate the process of managing your objects, making it easier to keep your S3 bucket organized and optimized for performance and cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ed387-2112-4cb7-8cf1-649ccedce2eb",
   "metadata": {},
   "source": [
    "### Replication Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac2ed4-7db4-4180-b8e3-065ddef26ec8",
   "metadata": {},
   "source": [
    "Replication rules are a feature that allow you to replicate your S3 objects to another S3 bucket located in a different region. With replication rules, you can protect your data against data loss or availability issues in a specific region.\n",
    "\n",
    "When you create a replication rule, it applies to all objects within a specific S3 bucket. You can use replication rules to replicate all objects within a bucket or only specific objects based on object tags or prefixes. Additionally, you can set up replication rules to replicate objects in real-time or asynchronously, depending on your specific requirements.\n",
    "\n",
    "You can create replication rules using the AWS Management Console or programmatically using the S3 API or AWS SDKs. By using replication rules, you can ensure that your data is protected against data loss or availability issues in a specific region, and you can also ensure that your data is available in multiple regions for low-latency access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205c582-baf4-45f8-98f1-deac8f391c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
